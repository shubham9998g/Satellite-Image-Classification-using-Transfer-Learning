# ğŸ–¼ï¸ Image Classification using Transfer Learning  
### âš™ï¸ VGG16 & MobileNetV2

---

## ğŸ“Œ Overview
This project implements an **image classification pipeline using transfer learning** with two industry-standard convolutional neural networks:

- **VGG16** â€“ accuracy-focused, high-capacity CNN  
- **MobileNetV2** â€“ lightweight, mobile-optimized CNN  

Both models use **ImageNet pre-trained weights** as feature extractors and are extended with custom classification heads.  
The project is designed and executed in **Google Colab**, with datasets stored in **Google Drive**.

---

## âœ¨ Key Features
- ğŸ” Transfer learning with **VGG16** and **MobileNetV2**
- ğŸ§  Modular model pipeline for architecture comparison
- ğŸ–¼ï¸ Image preprocessing and augmentation
- â„ï¸ Frozen base models to reduce overfitting
- ğŸ“Š Quantitative evaluation using standard ML metrics
- ğŸ“ˆ Visualization of training and validation performance

---

## ğŸ§° Tech Stack
- ğŸ **Python**
- ğŸ§  **TensorFlow / Keras**
- ğŸ“ **NumPy**
- ğŸ“Š **Matplotlib & Seaborn**
- ğŸ“‰ **Scikit-learn**
- â˜ï¸ **Google Colab + Google Drive**

---

## ğŸ§  Models Used

### ğŸ”¹ VGG16
- Deep convolutional neural network
- High representational capacity
- Suitable for accuracy-driven experiments
- Higher memory and compute cost

### ğŸ”¹ MobileNetV2
- Lightweight architecture using depthwise separable convolutions
- Optimized for speed and low-resource environments
- Suitable for mobile and edge deployment

> Both models are initialized with `include_top=False` and **ImageNet weights**.

---

## ğŸ—ï¸ Model Architecture (Common Head)
- Base Model: **VGG16 / MobileNetV2** (frozen)
- Global Average Pooling
- Dense layer (ReLU)
- Dropout (regularization)
- Dense output layer (Softmax)

---

## ğŸ“‚ Dataset Structure
The dataset must follow the structure below:
dataset/
â”‚â”€â”€ train/
â”‚ â”œâ”€â”€ class_1/
â”‚ â”œâ”€â”€ class_2/
â”‚ â””â”€â”€ ...
â”‚
â”‚â”€â”€ val/
â”‚ â”œâ”€â”€ class_1/
â”‚ â”œâ”€â”€ class_


ğŸ“Œ Each folder name is automatically treated as a **class label**.

---

## âš™ï¸ Training Configuration

| Parameter | Value |
|---------|-------|
| ğŸ–¼ï¸ Image Size | 224 Ã— 224 |
| ğŸ“¦ Batch Size | 200 |
| âš¡ Optimizer | Adam |
| ğŸ¯ Loss Function | Categorical Crossentropy |
| ğŸ“ˆ Metrics | Accuracy |
| ğŸ”„ Data Augmentation | Enabled (train only) |

---

## ğŸ“Š Evaluation Metrics
- âœ… Accuracy
- ğŸ“ Precision
- ğŸ” Recall
- ğŸ§® F1-Score
- ğŸ“‰ Confusion Matrix

Predictions are evaluated using **`sklearn.metrics`** for objective comparison.

---

## â–¶ï¸ How to Run
1. Open the notebook in **Google Colab**
2. Mount **Google Drive**
3. Verify dataset paths
4. Run cells sequentially:
   1. Load dataset
   2. Initialize models
   3. Train VGG16
   4. Train MobileNetV2
   5. Evaluate and visualize results

---

## ğŸ“¤ Outputs
- ğŸ§  Trained VGG16-based classifier
- âš¡ Trained MobileNetV2-based classifier
- ğŸ“ˆ Accuracy & loss plots
- ğŸ”¥ Confusion matrix heatmaps
- ğŸ§¾ Classification reports for both models

---

## âš–ï¸ Comparative Insight
- **VGG16** â†’ better representational power, higher resource usage
- **MobileNetV2** â†’ faster training and inference, lower memory footprint

ğŸ“Œ The project demonstrates **accuracy vs efficiency trade-offs** in real-world ML systems.

---

## ğŸš€ Future Enhancements
- ğŸ”“ Fine-tune upper convolutional layers
- ğŸ“‰ Add learning-rate scheduling
- ğŸ’¾ Save and reload trained models
- ğŸ–¼ï¸ Add single-image inference script
- â±ï¸ Benchmark inference latency and model size

---

## ğŸ¯ Use Cases
- ğŸ“ Academic transfer learning experiments
- ğŸ§ª CNN architecture comparison
- ğŸ“Œ Baseline for vision-based ML projects
- ğŸ“± Edge vs cloud deployment analysis

